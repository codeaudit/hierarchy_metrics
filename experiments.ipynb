{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for hierarchical graph clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents experiments related to two metrics for assessing the quality of hierarchical graph clustering, the relative entropy and Dasgupta's cost.\n",
    "\n",
    "Let ${\\cal T}$ be a binary tree representing the hierarchical structure of a graph.\n",
    "\n",
    "The **relative entropy** is defined by:\n",
    "$$\n",
    " \\sum_{A,B: (A,B) \\in {\\cal I}}p(A,B) \\log \\frac{p(A,B)}{\\pi(A) \\pi(B)},\n",
    "$$\n",
    "where:\n",
    "* ${\\cal I}$ is the set of internal nodes of the tree ${\\cal T}$ \n",
    "* $A,B$ are the sets of nodes induced by each element of ${\\cal I}$\n",
    "* $p(A,B)$ is the sampling probability of the node sets $A,B$\n",
    "* $\\pi(A)$ is the sampling probability of the node set $A$\n",
    "\n",
    "This is the Kullback-Leibler divergence between the  probability distribution on node sets  induced by the tree ${\\cal T}$ and that induced by independent node sampling from the   distribution $\\pi$. \n",
    "\n",
    "**Dasgupta's cost** is defined by:\n",
    "$$\n",
    "\\sum_{A,B: (A,B) \\in {\\cal I}}p(A,B) (\\pi(A)  + \\pi(B)).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hierarchy_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = nx.karate_club_graph()\n",
    "dendrogram = hierarchical_clustering(graph, algorithm = \"newman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"http://perso.telecom-paristech.fr/~bonald/graphs/\"\n",
    "\n",
    "# Openflights\n",
    "dataset = \"openflights.graphml.gz\"\n",
    "# Wikipedia for schools\n",
    "#dataset = \"wikipedia_schools_undirected.graphml.gz\"\n",
    "\n",
    "download = urllib.request.urlretrieve(url + dataset, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = nx.read_graphml(dataset, node_type=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Openflights\n",
      "Type: Graph\n",
      "Number of nodes: 3097\n",
      "Number of edges: 18193\n",
      "Average degree:  11.7488\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of samples for the random algorithm\n",
    "number_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dendrogram_paris = hierarchical_clustering(graph, \"paris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dendrogram_newman = hierarchical_clustering(graph, \"newman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dendrogram_random = [hierarchical_clustering(graph, \"random\") for s in range(number_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative entropy (weighted, uniform)\n",
      "Paris hierarchy:  2.7735716948816957 2.9113663048934426\n",
      "Newman hierarchy:  2.02722899031336 3.5131042696737222\n"
     ]
    }
   ],
   "source": [
    "print('Relative entropy (weighted, uniform)')\n",
    "print('Paris hierarchy: ', relative_entropy(graph, dendrogram_paris), relative_entropy(graph, dendrogram_paris, False))\n",
    "print('Newman hierarchy: ', relative_entropy(graph, dendrogram_newman), relative_entropy(graph, dendrogram_newman, False))\n",
    "#print('Random hierarchy: ', np.mean([relative_entropy(graph, d) for d in dendrogram_random]),np.mean([relative_entropy(graph, d, False) for d in dendrogram_random]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dasgupta cost (weighted, uniform)\n",
      "Paris hierarchy:  0.16716504372119464 0.12967721944804603\n",
      "Newman hierarchy:  0.24642084053212826 0.1383132701120162\n"
     ]
    }
   ],
   "source": [
    "print('Dasgupta cost (weighted, uniform)')\n",
    "print('Paris hierarchy: ', dasgupta_cost(graph, dendrogram_paris), dasgupta_cost(graph, dendrogram_paris, False))\n",
    "print('Newman hierarchy: ', dasgupta_cost(graph, dendrogram_newman), dasgupta_cost(graph, dendrogram_newman, False))\n",
    "#print('Random hierarchy: ', np.mean([dasgupta_cost(graph, d) for d in dendrogram_random]), np.mean([dasgupta_cost(graph, d, False) for d in dendrogram_random])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_dendrogram(number_nodes = 100):\n",
    "    nodes = list(range(number_nodes))\n",
    "    dendrogram = []\n",
    "    t = 0\n",
    "    size = {u: 1 for u in nodes}\n",
    "    while (len(nodes)) > 1:\n",
    "        u = nodes.pop(np.random.randint(len(nodes)))\n",
    "        v = nodes.pop(np.random.randint(len(nodes)))\n",
    "        new_node = number_nodes + t\n",
    "        t += 1\n",
    "        size[new_node] = size.pop(u) + size.pop(v)\n",
    "        dendrogram.append([u,v,size[new_node],size[new_node]])\n",
    "        nodes.append(new_node)\n",
    "    return np.array(dendrogram, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_similarity(dendrogram):\n",
    "    n = np.shape(dendrogram)[0] + 1\n",
    "    sim = np.zeros((n,n),float)\n",
    "    cluster = {u:[u] for u in range(n)}\n",
    "    for t in range(n - 1):\n",
    "        u = int(dendrogram[t][0])\n",
    "        v = int(dendrogram[t][1])\n",
    "        for i in cluster[u]:\n",
    "            for j in cluster[v]:\n",
    "                sim[i][j] = 1 / dendrogram[t][2]\n",
    "        cluster[n + t] = cluster.pop(u) + cluster.pop(v)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_graph(dendrogram, average_degree = 10):\n",
    "    n = np.shape(dendrogram)[0] + 1\n",
    "    similarity = get_similarity(dendrogram)\n",
    "    is_connected = False\n",
    "    while not is_connected:\n",
    "        adjacency = np.random.rand(n,n) < similarity / np.sum(similarity) * n * average_degree / 2\n",
    "        adjacency = np.array(adjacency + adjacency.T,int)\n",
    "        graph = nx.from_numpy_matrix(adjacency)\n",
    "        is_connected = nx.is_connected(graph)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise(graph, prob = 0.1):\n",
    "    is_connected = False\n",
    "    while not is_connected:\n",
    "        new_graph = graph.copy()\n",
    "        edges = list(graph.edges())\n",
    "        indices = np.random.choice(list(range(len(edges))),replace = False, size = int(np.floor(prob * len(edges))))\n",
    "        for i in indices:\n",
    "            u,v = edges[i]\n",
    "            new_graph.remove_edge(u,v)\n",
    "            new_edge = np.random.choice(list(new_graph.nodes()), replace = False, size = 2)\n",
    "            new_graph.add_edge(new_edge[0],new_edge[1],weight = 1.)\n",
    "        is_connected = nx.is_connected(new_graph)\n",
    "    return new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_scores(number_nodes, average_degree, prob_range, number_samples, algorithm, weighted = True):\n",
    "    results = []\n",
    "    for prob in prob_range:\n",
    "        cost = 0.\n",
    "        quality = 0.\n",
    "        for s in range(number_samples):\n",
    "            dendrogram = random_dendrogram(number_nodes)\n",
    "            graph = generate_graph(dendrogram, average_degree)\n",
    "            graph1 = add_noise(graph,prob)\n",
    "            graph2 = add_noise(graph,prob)\n",
    "            dendrogram1 = hierarchical_clustering(graph1, algorithm)\n",
    "            dendrogram2 = hierarchical_clustering(graph2, algorithm)\n",
    "            cost += (dasgupta_cost(graph1, dendrogram1, weighted) < dasgupta_cost(graph1, dendrogram2, weighted))\n",
    "            cost += (dasgupta_cost(graph2, dendrogram2, weighted) < dasgupta_cost(graph2, dendrogram1, weighted))\n",
    "            quality += (relative_entropy(graph1, dendrogram1, weighted) > relative_entropy(graph1, dendrogram2, weighted))\n",
    "            quality += (relative_entropy(graph2, dendrogram2, weighted) > relative_entropy(graph2, dendrogram1, weighted))\n",
    "        results.append((cost / 2 / number_samples, quality / 2 / number_samples))\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_nodes = 100\n",
    "average_degree = 10\n",
    "prob_range = np.arange(0.01,0.2,0.03)\n",
    "number_samples = 1000\n",
    "results_paris = classification_scores(number_nodes, average_degree, prob_range, number_samples, \"paris\", True)\n",
    "results_newman = classification_scores(number_nodes, average_degree, prob_range, number_samples, \"newman\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(100 * prob_range,100 * results_paris[:,1],label = 'Entropy', color = \"b\")\n",
    "plt.plot(100 * prob_range,100 * results_paris[:,0],'--',label = 'Dasgupta',color = \"b\")\n",
    "plt.plot(100 * prob_range,100 * results_newman[:,1], color = \"r\")\n",
    "plt.plot(100 * prob_range,100 * results_newman[:,0],'--',color = \"r\")\n",
    "plt.xticks(np.arange(0, 21, step=5))\n",
    "plt.xlabel(\"Graph distance (%)\")\n",
    "plt.ylabel(\"Classification score (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
